{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can create tensors (vectors, matrices, etc) just as we could in numpy.\n",
    "\n",
    "- zeros\n",
    "- ones\n",
    "- random [0,1], random normal, whatever distribution you like\n",
    "- empty\n",
    "- \"like\" other matrices\n",
    "- from lists, numpy arrays...\n",
    "- copy vs clone\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zeros\n",
    "x = torch.zeros(5,5)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.ndim)\n",
    "\n",
    "# ones\n",
    "ones = torch.ones(3,3)\n",
    "print(ones)\n",
    "print(ones.shape)\n",
    "print(ones.ndim)\n",
    "\n",
    "# identity matrices\n",
    "I = torch.eye(5)\n",
    "print(I)\n",
    "print(I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uniform random\n",
    "r = torch.rand(2,3,4)\n",
    "print(r)\n",
    "print(r.shape)\n",
    "print(r.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard normal distribution\n",
    "rnorm = torch.randn(100000,)\n",
    "print(rnorm.shape)\n",
    "print(rnorm.ndim)\n",
    "print(rnorm.mean(), rnorm.var())\n",
    "print(rnorm.mean().item())\n",
    "print(rnorm.var().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"empty\"\n",
    "empt = torch.empty(5,5)\n",
    "print(empt)\n",
    "print(empt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"_like\"\n",
    "z = torch.zeros_like(empt)\n",
    "print(z)\n",
    "print(z.shape)\n",
    "\n",
    "z = torch.empty_like(z)\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from numpy\n",
    "n = np.random.random((5,4,3,2))\n",
    "print(n.shape)\n",
    "\n",
    "ntorch = torch.from_numpy(n)\n",
    "print(ntorch.shape)\n",
    "\n",
    "ntorch2 = torch.tensor(n)\n",
    "print(ntorch2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy vs clone\n",
    "\n",
    "x = torch.rand(3,3)\n",
    "print(x)\n",
    "x_copied = x\n",
    "x[0,0] = 10\n",
    "print(x_copied)\n",
    "\n",
    "x_cloned = x.clone()\n",
    "x[0,0] = -9999\n",
    "print(x_cloned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can check aspects of the tensor: \n",
    "\n",
    "-device\n",
    "-size\n",
    "-shape\n",
    "-dimensions\n",
    "-slice it\n",
    "-subset it\n",
    "-argmax, max\n",
    "- concateate/stack\n",
    "- reshape\n",
    "- squeeze / unsqueeze\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device\n",
    "n = torch.randn((5,3,4,2), device='cpu') # cuda\n",
    "print(n.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# size/shape\n",
    "print(n.size())\n",
    "print(n.shape)\n",
    "print(n.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slice and subset\n",
    "n0 = n[0]\n",
    "print(n0.shape)\n",
    "\n",
    "print(n[:3].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max/argmax\n",
    "r = torch.rand(1000,)\n",
    "argmax = r.argmax()\n",
    "print(argmax)\n",
    "print(argmax.item())\n",
    "print(r[argmax.item()])\n",
    "print(r.max())\n",
    "r.max() == r[argmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatenate/stack\n",
    "\n",
    "x1 = torch.rand(2,3,4)\n",
    "x2 = torch.rand(5,3,4)\n",
    "concatenated = torch.cat((x1,x2))\n",
    "print(concatenated.shape)\n",
    "\n",
    "\n",
    "vstacked = torch.vstack((x1,x2))\n",
    "print(vstacked.shape)\n",
    "\n",
    "x3 = torch.rand(7,6,4)\n",
    "hstacked = torch.hstack((concatenated, x3))\n",
    "print(hstacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reshape\n",
    "x = torch.randn(100,)\n",
    "print(x.shape)\n",
    "x_reshaped = x.reshape((10,10))\n",
    "print(x_reshaped.shape)\n",
    "x = x_reshaped.reshape((2,2,5,5))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# squeeze, unsqueeze\n",
    "silly_shape = torch.ones(1,1,1,1,1,1,1,3,3)\n",
    "print(silly_shape.shape)\n",
    "print(silly_shape)\n",
    "\n",
    "cleaned_up = silly_shape.squeeze()\n",
    "print(cleaned_up.shape)\n",
    "print(cleaned_up)\n",
    "\n",
    "a_bit_less_cleaned_up  = cleaned_up.unsqueeze(0)\n",
    "print(a_bit_less_cleaned_up.shape)\n",
    "a_bit_less_cleaned_up  = cleaned_up.unsqueeze(1)\n",
    "print(a_bit_less_cleaned_up.shape)\n",
    "a_bit_less_cleaned_up  = cleaned_up.unsqueeze(2)\n",
    "print(a_bit_less_cleaned_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can do regular mathematical (scientific computing) operations on these matrices.\n",
    "\n",
    "- tranpose, permutations\n",
    "- cosine, arccos\n",
    "- matrix multiplication\n",
    "- dot product\n",
    "- inplace addition\n",
    "- clamp\n",
    "- norm and normalize\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transpose and permutations\n",
    "m = torch.randint(-10,10,(3,4))\n",
    "print(m.shape)\n",
    "print(m)\n",
    "print(\"Here comes the transpose\")\n",
    "print(m.t())\n",
    "print(m.t().shape)\n",
    "\n",
    "permuted = torch.permute(m, (1,0))\n",
    "print(permuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# of course, if you have a tensor of shape (Batch_size, num_channels, height, width) of images, you can re-arrange things too\n",
    "BATCH_SIZE = 32\n",
    "NUM_CHANNELS = 3\n",
    "HEIGHT = 120\n",
    "WIDTH = 120\n",
    "\n",
    "batch_data = torch.rand(BATCH_SIZE, NUM_CHANNELS, HEIGHT, WIDTH)\n",
    "print(batch_data.shape)\n",
    "\n",
    "permuted_batch_data = torch.permute(batch_data, (1,0,2,3))\n",
    "print(permuted_batch_data.shape)\n",
    "print(\"Shape: (num_channels, batch_size, height, width)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cosine, arccos\n",
    "thetas = torch.arange(-2*torch.pi, 2*torch.pi, 0.1)\n",
    "cosines = torch.cos(thetas)\n",
    "plt.plot(thetas, cosines)\n",
    "plt.title(\"Cosine like a boss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# matrix multiplication\n",
    "m1 = torch.randn((3,4))\n",
    "m2 = torch.randn((4,5))\n",
    "m3 = m1.mm(m2) # using tensor functions\n",
    "print(m3.shape)\n",
    "\n",
    "# or use torch\n",
    "m4 = torch.matmul(m1, m2)\n",
    "print(m4.shape)\n",
    "\n",
    "print(m4 == m3)\n",
    "print(m4.eq(m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inner and outer products\n",
    "vec1 = torch.randn(10)\n",
    "vec2 = torch.randn(10)\n",
    "\n",
    "dot = torch.inner(vec1, vec2)\n",
    "print(dot)\n",
    "\n",
    "# multi-dim tensors\n",
    "tensor = torch.randn((2,3,10))\n",
    "dot = torch.inner(tensor, vec1)\n",
    "print(dot.shape)\n",
    "\n",
    "# outer product\n",
    "print(torch.outer(vec1, vec2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inplace addition\n",
    "print(vec1)\n",
    "vec1.add_(vec2)\n",
    "print(vec1)\n",
    "vec1.add_(-10)\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clamp\n",
    "m = torch.randn((4,4))\n",
    "print(m)\n",
    "low_cutoff = -0.8\n",
    "high_cutoff = 0.5\n",
    "clamped_m = m.clamp(low_cutoff, high_cutoff)\n",
    "print(clamped_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# norm and normalize\n",
    "x = torch.randn(5)\n",
    "print(x)\n",
    "print(\"L1 norm\")\n",
    "print(x.norm(p=1))\n",
    "print(abs(x).sum())\n",
    "print(\"L2 norm\")\n",
    "print(x.norm(p=2))\n",
    "print((x**2).sum().sqrt())\n",
    "\n",
    "print(\"Project onto L2 ball with radius 1 (aka 'normalize')\")\n",
    "\n",
    "x_proj = F.normalize(x, p=2, dim=0)\n",
    "print(x_proj)\n",
    "print(x_proj.norm(p=2))\n",
    "\n",
    "# do it by hand\n",
    "x.div_(x.norm(p=2))\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
